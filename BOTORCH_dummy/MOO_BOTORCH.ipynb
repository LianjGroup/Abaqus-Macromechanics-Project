{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b34a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.acquisition.multi_objective import qExpectedHypervolumeImprovement\n",
    "\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.utils.multi_objective.box_decompositions import NondominatedPartitioning\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "# standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# minmax scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Define your custom loss function\n",
    "\n",
    "from ax.service.ax_client import AxClient\n",
    "from ax.service.utils.instantiation import ObjectiveProperties\n",
    "from botorch.utils.transforms import *\n",
    "import torch\n",
    "import botorch\n",
    "# Plotting imports and initialization\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "from ax.plot.pareto_utils import compute_posterior_pareto_frontier\n",
    "from ax.plot.pareto_frontier import plot_pareto_frontier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad7338ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining everything for dummy testing\n",
    "\n",
    "param_bounds = {\n",
    "    'c1': {'lowerBound': 0, 'upperBound': 1, 'exponent': 1.0, 'name': 'W', 'unit': 'dimensionless', 'type': 'hardening'}, \n",
    "    'c2': {'lowerBound': 0, 'upperBound': 2, 'exponent': 1000.0, 'name': 'K', 'unit': 'MPa', 'type': 'yielding'}, \n",
    "    'c3': {'lowerBound': 0, 'upperBound': 1, 'exponent': 0.1, 'name': 'e0', 'unit': 'dimensionless', 'type': 'hardening'}, \n",
    "    'c4': {'lowerBound': 0, 'upperBound': 1, 'exponent': 1.0, 'name': 'n', 'unit': 'dimensionless', 'type': 'hardening'}, \n",
    "    'c5': {'lowerBound': 0, 'upperBound': 2, 'exponent': 1000.0, 'name': 'sigma_y', 'unit': 'MPa', 'type': 'yielding'}, \n",
    "    'c6': {'lowerBound': 0, 'upperBound': 1, 'exponent': 1000.0, 'name': 'sigma_sat', 'unit': 'MPa', 'type': 'hardening'}, \n",
    "    'c7': {'lowerBound': 0, 'upperBound': 1, 'exponent': 1000.0, 'name': 'b', 'unit': 'dimensionless', 'type': 'hardening'}\n",
    "}\n",
    "\n",
    "\n",
    "geometries = ['NDBR50', 'NDBR6', 'CHD6']\n",
    "\n",
    "def calculate_loss(simulated_curve, target_curve):\n",
    "    # This is a placeholder. Replace this with your actual loss function.\n",
    "    return np.mean(np.sum((simulated_curve - target_curve)**2))\n",
    "\n",
    "\n",
    "def generate_dummy_target_curves():\n",
    "    geometries = ['NDBR50', 'NDBR6', 'CHD6']\n",
    "    targetCurves = {geometry: {'force': np.random.rand(100), 'displacement': np.linspace(0, 2, 100)} for geometry in geometries}\n",
    "    return targetCurves\n",
    "\n",
    "def generate_dummy_combined_data():\n",
    "    geometries = ['NDBR50', 'NDBR6', 'CHD6']\n",
    "    params = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7']\n",
    "    combined_data = {\n",
    "        tuple((param, np.random.rand()) for param in params): \n",
    "        {geometry: {'force': np.random.rand(100), 'displacement': np.linspace(0, 2, 100)} for geometry in geometries}\n",
    "        for _ in range(100)\n",
    "    }\n",
    "    return combined_data\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def scale_dataset(data):\n",
    "    # Step 1: Calculate min and max values along each dimension\n",
    "    min_vals = np.min(data, axis=0)\n",
    "    max_vals = np.max(data, axis=0)\n",
    "\n",
    "    # Step 2: Perform min-max scaling\n",
    "    scaled_data = (data - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    # Step 3: Calculate means along each dimension\n",
    "    mean_vals = np.mean(scaled_data, axis=0)\n",
    "\n",
    "    # Step 4: Perform mean normalization\n",
    "    normalized_data = scaled_data - mean_vals\n",
    "\n",
    "    return normalized_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2b32f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15221789 0.15649037 0.16322542]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\models\\utils\\assorted.py:201: InputDataWarning:\n",
      "\n",
      "Input data is not standardized. Please consider scaling the input to zero mean and unit variance.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 63\u001b[0m\n\u001b[0;32m     54\u001b[0m acq_func \u001b[39m=\u001b[39m qExpectedHypervolumeImprovement(\n\u001b[0;32m     55\u001b[0m     model\u001b[39m=\u001b[39mgp, \n\u001b[0;32m     56\u001b[0m     ref_point\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mzeros(scaled_losses\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]),\n\u001b[0;32m     57\u001b[0m     partitioning\u001b[39m=\u001b[39mpartitioning,\n\u001b[0;32m     58\u001b[0m )\n\u001b[0;32m     60\u001b[0m \u001b[39m# acq_func = q\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[39m# Optimize the acquisition function to find the next set of parameters to evaluate\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m candidates, _ \u001b[39m=\u001b[39m optimize_acqf(\n\u001b[0;32m     64\u001b[0m     acq_function\u001b[39m=\u001b[39;49macq_func,\n\u001b[0;32m     65\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[0;32m     66\u001b[0m     q\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,  \u001b[39m# change this to the number of candidates you want to generate\u001b[39;49;00m\n\u001b[0;32m     67\u001b[0m     num_restarts\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[0;32m     68\u001b[0m     raw_samples\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     69\u001b[0m )\n\u001b[0;32m     71\u001b[0m \u001b[39m# Denormalize the candidates\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m# next_params = minmax_scaler.inverse_transform(candidates.detach().numpy())\u001b[39;00m\n\u001b[0;32m     73\u001b[0m next_params \u001b[39m=\u001b[39m std_scaler\u001b[39m.\u001b[39minverse_transform(candidates\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\optim\\optimize.py:544\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[1;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m     gen_candidates \u001b[39m=\u001b[39m gen_candidates_scipy\n\u001b[0;32m    522\u001b[0m opt_acqf_inputs \u001b[39m=\u001b[39m OptimizeAcqfInputs(\n\u001b[0;32m    523\u001b[0m     acq_function\u001b[39m=\u001b[39macq_function,\n\u001b[0;32m    524\u001b[0m     bounds\u001b[39m=\u001b[39mbounds,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m     ic_gen_kwargs\u001b[39m=\u001b[39mic_gen_kwargs,\n\u001b[0;32m    543\u001b[0m )\n\u001b[1;32m--> 544\u001b[0m \u001b[39mreturn\u001b[39;00m _optimize_acqf(opt_acqf_inputs)\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\optim\\optimize.py:573\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[1;34m(opt_inputs)\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[39mreturn\u001b[39;00m _optimize_acqf_sequential_q(\n\u001b[0;32m    567\u001b[0m         opt_inputs\u001b[39m=\u001b[39mopt_inputs,\n\u001b[0;32m    568\u001b[0m         timeout_sec\u001b[39m=\u001b[39mtimeout_sec,\n\u001b[0;32m    569\u001b[0m         start_time\u001b[39m=\u001b[39mstart_time,\n\u001b[0;32m    570\u001b[0m     )\n\u001b[0;32m    572\u001b[0m \u001b[39m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[1;32m--> 573\u001b[0m \u001b[39mreturn\u001b[39;00m _optimize_acqf_batch(\n\u001b[0;32m    574\u001b[0m     opt_inputs\u001b[39m=\u001b[39;49mopt_inputs, start_time\u001b[39m=\u001b[39;49mstart_time, timeout_sec\u001b[39m=\u001b[39;49mtimeout_sec\n\u001b[0;32m    575\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\optim\\optimize.py:351\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[1;34m(opt_inputs, start_time, timeout_sec)\u001b[0m\n\u001b[0;32m    348\u001b[0m         batch_acq_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(batch_acq_values_list)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m    349\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_candidates, batch_acq_values, opt_warnings\n\u001b[1;32m--> 351\u001b[0m batch_candidates, batch_acq_values, ws \u001b[39m=\u001b[39m _optimize_batch_candidates(timeout_sec)\n\u001b[0;32m    353\u001b[0m optimization_warning_raised \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[0;32m    354\u001b[0m     (\u001b[39missubclass\u001b[39m(w\u001b[39m.\u001b[39mcategory, OptimizationWarning) \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m ws)\n\u001b[0;32m    355\u001b[0m )\n\u001b[0;32m    356\u001b[0m \u001b[39mif\u001b[39;00m optimization_warning_raised \u001b[39mand\u001b[39;00m opt_inputs\u001b[39m.\u001b[39mretry_on_optimization_warning:\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\optim\\optimize.py:335\u001b[0m, in \u001b[0;36m_optimize_acqf_batch.<locals>._optimize_batch_candidates\u001b[1;34m(timeout_sec)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m ws:\n\u001b[0;32m    331\u001b[0m     warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39malways\u001b[39m\u001b[39m\"\u001b[39m, category\u001b[39m=\u001b[39mOptimizationWarning)\n\u001b[0;32m    332\u001b[0m     (\n\u001b[0;32m    333\u001b[0m         batch_candidates_curr,\n\u001b[0;32m    334\u001b[0m         batch_acq_values_curr,\n\u001b[1;32m--> 335\u001b[0m     ) \u001b[39m=\u001b[39m opt_inputs\u001b[39m.\u001b[39;49mgen_candidates(\n\u001b[0;32m    336\u001b[0m         batched_ics_, opt_inputs\u001b[39m.\u001b[39;49macq_function, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfiltered_gen_kwargs\n\u001b[0;32m    337\u001b[0m     )\n\u001b[0;32m    338\u001b[0m opt_warnings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m ws\n\u001b[0;32m    339\u001b[0m batch_candidates_list\u001b[39m.\u001b[39mappend(batch_candidates_curr)\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\generation\\gen.py:232\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[1;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39macquisition_function(x)\n\u001b[1;32m--> 232\u001b[0m res \u001b[39m=\u001b[39m minimize_with_timeout(\n\u001b[0;32m    233\u001b[0m     fun\u001b[39m=\u001b[39;49mf_np_wrapper,\n\u001b[0;32m    234\u001b[0m     args\u001b[39m=\u001b[39;49m(f,),\n\u001b[0;32m    235\u001b[0m     x0\u001b[39m=\u001b[39;49mx0,\n\u001b[0;32m    236\u001b[0m     method\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mSLSQP\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m constraints \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    237\u001b[0m     jac\u001b[39m=\u001b[39;49mwith_grad,\n\u001b[0;32m    238\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[0;32m    239\u001b[0m     constraints\u001b[39m=\u001b[39;49mconstraints,\n\u001b[0;32m    240\u001b[0m     callback\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallback\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    241\u001b[0m     options\u001b[39m=\u001b[39;49m{\n\u001b[0;32m    242\u001b[0m         k: v\n\u001b[0;32m    243\u001b[0m         \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m options\u001b[39m.\u001b[39;49mitems()\n\u001b[0;32m    244\u001b[0m         \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcallback\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mwith_grad\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m    245\u001b[0m     },\n\u001b[0;32m    246\u001b[0m     timeout_sec\u001b[39m=\u001b[39;49mtimeout_sec,\n\u001b[0;32m    247\u001b[0m )\n\u001b[0;32m    248\u001b[0m _process_scipy_result(res\u001b[39m=\u001b[39mres, options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m    250\u001b[0m candidates \u001b[39m=\u001b[39m fix_features(\n\u001b[0;32m    251\u001b[0m     X\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfrom_numpy(res\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mto(initial_conditions)\u001b[39m.\u001b[39mreshape(shapeX),\n\u001b[0;32m    252\u001b[0m     fixed_features\u001b[39m=\u001b[39mfixed_features,\n\u001b[0;32m    253\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\optim\\utils\\timeout.py:80\u001b[0m, in \u001b[0;36mminimize_with_timeout\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[0;32m     77\u001b[0m     wrapped_callback \u001b[39m=\u001b[39m callback\n\u001b[0;32m     79\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[0;32m     81\u001b[0m         fun\u001b[39m=\u001b[39;49mfun,\n\u001b[0;32m     82\u001b[0m         x0\u001b[39m=\u001b[39;49mx0,\n\u001b[0;32m     83\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m     84\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[0;32m     85\u001b[0m         jac\u001b[39m=\u001b[39;49mjac,\n\u001b[0;32m     86\u001b[0m         hess\u001b[39m=\u001b[39;49mhess,\n\u001b[0;32m     87\u001b[0m         hessp\u001b[39m=\u001b[39;49mhessp,\n\u001b[0;32m     88\u001b[0m         bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[0;32m     89\u001b[0m         constraints\u001b[39m=\u001b[39;49mconstraints,\n\u001b[0;32m     90\u001b[0m         tol\u001b[39m=\u001b[39;49mtol,\n\u001b[0;32m     91\u001b[0m         callback\u001b[39m=\u001b[39;49mwrapped_callback,\n\u001b[0;32m     92\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m     93\u001b[0m     )\n\u001b[0;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m OptimizationTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     95\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOptimization timed out after \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mruntime\u001b[39m}\u001b[39;00m\u001b[39m seconds.\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    693\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    694\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    695\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 696\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    697\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[0;32m    698\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    699\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    700\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    353\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    360\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[0;32m     75\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 70\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[0;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\generation\\gen.py:190\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f_np_wrapper\u001b[1;34m(x, f)\u001b[0m\n\u001b[0;32m    182\u001b[0m X \u001b[39m=\u001b[39m (\n\u001b[0;32m    183\u001b[0m     torch\u001b[39m.\u001b[39mfrom_numpy(x)\n\u001b[0;32m    184\u001b[0m     \u001b[39m.\u001b[39mto(initial_conditions)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m )\n\u001b[0;32m    189\u001b[0m X_fix \u001b[39m=\u001b[39m fix_features(X, fixed_features\u001b[39m=\u001b[39mfixed_features)\n\u001b[1;32m--> 190\u001b[0m loss \u001b[39m=\u001b[39m f(X_fix)\u001b[39m.\u001b[39msum()\n\u001b[0;32m    191\u001b[0m \u001b[39m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n\u001b[0;32m    192\u001b[0m gradf \u001b[39m=\u001b[39m _arrayify(torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(loss, X)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\generation\\gen.py:230\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39macquisition_function(x)\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\utils\\transforms.py:330\u001b[0m, in \u001b[0;36mconcatenate_pending_points.<locals>.decorated\u001b[1;34m(cls, X, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mX_pending \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([X, match_batch_shape(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mX_pending, X)], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 330\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mcls\u001b[39;49m, X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\utils\\transforms.py:287\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[1;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m# add t-batch dim\u001b[39;00m\n\u001b[0;32m    286\u001b[0m X \u001b[39m=\u001b[39m X \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 287\u001b[0m output \u001b[39m=\u001b[39m method(acqf, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(acqf, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m is_fully_bayesian(acqf\u001b[39m.\u001b[39mmodel):\n\u001b[0;32m    289\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\acquisition\\multi_objective\\monte_carlo.py:360\u001b[0m, in \u001b[0;36mqExpectedHypervolumeImprovement.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    358\u001b[0m posterior \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mposterior(X)\n\u001b[0;32m    359\u001b[0m samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_posterior_samples(posterior)\n\u001b[1;32m--> 360\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_qehvi(samples\u001b[39m=\u001b[39;49msamples, X\u001b[39m=\u001b[39;49mX)\n",
      "File \u001b[1;32mc:\\Users\\springnuance\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botorch\\acquisition\\multi_objective\\monte_carlo.py:328\u001b[0m, in \u001b[0;36mqExpectedHypervolumeImprovement._compute_qehvi\u001b[1;34m(self, samples, X)\u001b[0m\n\u001b[0;32m    322\u001b[0m obj_subsets \u001b[39m=\u001b[39m obj_subsets\u001b[39m.\u001b[39mview(\n\u001b[0;32m    323\u001b[0m     obj\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m q_choose_i\u001b[39m.\u001b[39mshape \u001b[39m+\u001b[39m obj\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[0;32m    324\u001b[0m )\n\u001b[0;32m    325\u001b[0m \u001b[39m# since all hyperrectangles share one vertex, the opposite vertex of the\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m# overlap is given by the component-wise minimum.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m# take the minimum in each subset\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m overlap_vertices \u001b[39m=\u001b[39m obj_subsets\u001b[39m.\u001b[39;49mmin(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39mvalues\n\u001b[0;32m    329\u001b[0m \u001b[39m# add batch-dim to compute area for each segment (pseudo-pareto-vertex)\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[39m# this tensor is mc_samples x batch_shape x num_cells x q_choose_i x m\u001b[39;00m\n\u001b[0;32m    331\u001b[0m overlap_vertices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(\n\u001b[0;32m    332\u001b[0m     overlap_vertices\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcell_upper_bounds\u001b[39m.\u001b[39mview(view_shape)\n\u001b[0;32m    333\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate dummy data\n",
    "combined_interpolated_param_to_geom_FD_Curves_smooth = np.load('combined_interpolated_param_to_geom_FD_Curves_smooth.npy', allow_pickle=True).tolist()\n",
    "\n",
    "targetCurves = np.load('targetCurves.npy', allow_pickle=True).tolist()\n",
    "\n",
    "# Convert your data to the required format\n",
    "params = []\n",
    "losses = []\n",
    "for param_tuple, geom_dict in combined_interpolated_param_to_geom_FD_Curves_smooth.items():\n",
    "    params.append([value for param, value in param_tuple])\n",
    "    losses.append([calculate_loss(geom_dict[geometry][\"force\"], targetCurves[geometry][\"force\"]) for geometry in geometries])\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the parameters\n",
    "params = torch.tensor(params, dtype=torch.float64)\n",
    "#scaled_params = std_scaler.fit_transform(params)\n",
    "scaled_params = minmax_scaler.fit_transform(params)\n",
    "scaled_params = torch.tensor(scaled_params, dtype=torch.float64)\n",
    "\n",
    "# losses = torch.tensor(losses, dtype=torch.float64)\n",
    "#scaled_losses = std_scaler.fit_transform(losses)\n",
    "scaled_losses = minmax_scaler.fit_transform(losses)\n",
    "print(np.std(scaled_losses, axis=0))\n",
    "scaled_losses = torch.tensor(scaled_losses, dtype=torch.float64)\n",
    "\n",
    "# print(params.shape)\n",
    "# (200, 7)\n",
    "# print(losses.shape)\n",
    "# (200, 3)\n",
    "\n",
    "# Train a GP model\n",
    "\n",
    "gp = SingleTaskGP(train_X=scaled_params, train_Y=scaled_losses)\n",
    "\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "# Define the bounds of the search space\n",
    "lower_bounds = torch.tensor([param_bounds[param]['lowerBound'] for param in param_bounds.keys()]).float()\n",
    "upper_bounds = torch.tensor([param_bounds[param]['upperBound'] for param in param_bounds.keys()]).float()\n",
    "\n",
    "bounds = torch.stack([lower_bounds, upper_bounds])\n",
    "\n",
    "# Define the reference point as slightly worse than the worst observed values\n",
    "ref_point = torch.zeros(scaled_losses.shape[1])\n",
    "\n",
    "# Define the partitioning of the output space\n",
    "partitioning = NondominatedPartitioning(ref_point=ref_point, Y=scaled_losses)\n",
    "\n",
    "# Define the acquisition function\n",
    "acq_func = qExpectedHypervolumeImprovement(\n",
    "    model=gp, \n",
    "    ref_point=torch.zeros(scaled_losses.shape[1]),\n",
    "    partitioning=partitioning,\n",
    ")\n",
    "\n",
    "# acq_func = q\n",
    "\n",
    "# Optimize the acquisition function to find the next set of parameters to evaluate\n",
    "candidates, _ = optimize_acqf(\n",
    "    acq_function=acq_func,\n",
    "    bounds=bounds,\n",
    "    q=10,  # change this to the number of candidates you want to generate\n",
    "    num_restarts=5,\n",
    "    raw_samples=10,\n",
    ")\n",
    "\n",
    "# Denormalize the candidates\n",
    "# next_params = minmax_scaler.inverse_transform(candidates.detach().numpy())\n",
    "next_params = std_scaler.inverse_transform(candidates.detach().numpy())\n",
    "\n",
    "# Convert the tensor to a list of dictionaries\n",
    "next_param_dicts = [{param: value.item() for param, value in zip(param_bounds.keys(), next_param)} for next_param in next_params]\n",
    "\n",
    "# Select the non-dominated solutions\n",
    "pareto_mask = is_non_dominated(torch.stack([gp.posterior(next_param.unsqueeze(0)).mean for next_param in next_params]))\n",
    "pareto_solutions = [next_param_dicts[i] for i in range(len(next_param_dicts)) if pareto_mask[i]]\n",
    "\n",
    "print(pareto_solutions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8dc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InputDataWarning:\n",
    "\n",
    "# Input data is not standardized. Please consider scaling the input to zero mean and unit variance.\n",
    "params_copy = params.copy()\n",
    "params = torch.tensor(params, dtype=torch.float64)\n",
    "# Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
    "# scaled_params = MinMaxScaler().fit_transform(params)\n",
    "# scaled_params = StandardScaler().fit_transform(params)\n",
    "\n",
    "bounds = [[-0.5 for _ in range(params.shape[1])], [0.5 for _ in range(params.shape[1])]]\n",
    "bounds = torch.tensor(bounds, dtype=torch.float64)\n",
    "# print(bounds.shape)\n",
    "\n",
    "# scaled_params = normalize(params, bounds=bounds)\n",
    "scaled_params = standardize(params)\n",
    "scaled_params = normalize(scaled_params, bounds=bounds)\n",
    "losses = torch.tensor(losses, dtype=torch.float64)\n",
    "\n",
    "#scaled_params = torch.tensor(scaled_params, dtype=torch.float64)\n",
    "bounds = [[-0.5 for _ in range(losses.shape[1])], [0.5 for _ in range(losses.shape[1])]]\n",
    "bounds = torch.tensor(bounds, dtype=torch.float64)\n",
    "\n",
    "#scaled_losses = MinMaxScaler().fit_transform(losses)\n",
    "#scaled_losses = StandardScaler().fit_transform(scaled_losses)\n",
    "#scaled_losses = torch.tensor(scaled_losses, dtype=torch.float64)\n",
    "\n",
    "#scaled_losses = normalize(losses, bounds=bounds)\n",
    "scaled_losses = standardize(losses)\n",
    "scaled_losses = normalize(scaled_losses, bounds=bounds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
