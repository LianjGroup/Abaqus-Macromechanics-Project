{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c2a7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zopev1\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.acquisition.multi_objective import qExpectedHypervolumeImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.utils.multi_objective.box_decompositions import NondominatedPartitioning\n",
    "from botorch.utils.multi_objective.pareto import is_non_dominated\n",
    "from botorch.utils import standardize\n",
    "from botorch.acquisition.multi_objective.objective import IdentityMCMultiOutputObjective\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130b0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramConfig = {\n",
    "    'c1': {'lowerBound': 0, 'upperBound': 1, 'exponent': 1.0, 'name': 'W', 'unit': 'dimensionless', 'type': 'hardening'}, \n",
    "    'c2': {'lowerBound': 0, 'upperBound': 2, 'exponent': 1000.0, 'name': 'K', 'unit': 'MPa', 'type': 'yielding'}, \n",
    "    'c3': {'lowerBound': 0, 'upperBound': 1, 'exponent': 0.1, 'name': 'e0', 'unit': 'dimensionless', 'type': 'hardening'}, \n",
    "    'c4': {'lowerBound': 0, 'upperBound': 1, 'exponent': 1.0, 'name': 'n', 'unit': 'dimensionless', 'type': 'hardening'}, \n",
    "    'c5': {'lowerBound': 0, 'upperBound': 2, 'exponent': 1000.0, 'name': 'sigma_y', 'unit': 'MPa', 'type': 'yielding'}, \n",
    "    'c6': {'lowerBound': 0, 'upperBound': 1, 'exponent': 1000.0, 'name': 'sigma_sat', 'unit': 'MPa', 'type': 'hardening'}, \n",
    "    'c7': {'lowerBound': 0, 'upperBound': 1, 'exponent': 1000.0, 'name': 'b', 'unit': 'dimensionless', 'type': 'hardening'}\n",
    "}\n",
    "\n",
    "geometries = ['NDBR50', 'NDBR6', 'CHD6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094207a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'c1': 0.02144253413953988, 'c2': 1029.3836305231819, 'c3': 0.04639085410225211, 'c4': 0.4592792981981647, 'c5': 1990.7990799079907, 'c6': 995.5995599559956, 'c7': 162.59976643713156}]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "combined_interpolated_param_to_geom_FD_Curves_smooth = np.load('combined_interpolated_param_to_geom_FD_Curves_smooth.npy', allow_pickle=True).tolist()\n",
    "targetCurves = np.load('targetCurves.npy', allow_pickle=True).tolist()\n",
    "\n",
    "# Define the function for the RMSE loss\n",
    "def lossFD(y, y_hat):\n",
    "    return torch.sqrt(torch.mean((y - y_hat)**2))\n",
    "\n",
    "# Calculate losses and prepare data for model\n",
    "params = []\n",
    "losses = []\n",
    "for param_tuple, geom_dict in combined_interpolated_param_to_geom_FD_Curves_smooth.items():\n",
    "    params.append([value for param, value in param_tuple])\n",
    "    losses.append([lossFD(torch.tensor(geom_dict[geometry][\"force\"]), torch.tensor(targetCurves[geometry][\"force\"])) for geometry in geometries])\n",
    "\n",
    "# Convert your data to the tensor(float 64)\n",
    "X = torch.tensor(params, dtype=torch.float64)\n",
    "Y = torch.stack([torch.tensor(loss, dtype=torch.float64) for loss in losses])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = torch.tensor(scaler.fit_transform(X.numpy()), dtype=torch.float64)\n",
    "\n",
    "# Standardize Y to have zero mean and unit variance\n",
    "Y_standardized = standardize(Y)\n",
    "\n",
    "# Define the bounds of the search space\n",
    "lower_bounds = torch.tensor([paramConfig[param]['lowerBound'] for param in paramConfig.keys()]).float()\n",
    "upper_bounds = torch.tensor([paramConfig[param]['upperBound'] for param in paramConfig.keys()]).float()\n",
    "#normalise the bounds in accordance to the normalised params\n",
    "bounds = torch.tensor([[0.0]*X_normalized.shape[1], [1.0]*X_normalized.shape[1]])\n",
    "\n",
    "# Initialize model\n",
    "model = SingleTaskGP(X_normalized, Y_standardized)\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "# Define the acquisition function\n",
    "ref_point = Y_standardized.max(dim=0).values - 0.01\n",
    "\n",
    "partitioning = NondominatedPartitioning(ref_point=ref_point, Y=Y_standardized)\n",
    "acq_func = qExpectedHypervolumeImprovement(\n",
    "    model=model,\n",
    "    partitioning=partitioning,\n",
    "    ref_point=ref_point,\n",
    "    objective=IdentityMCMultiOutputObjective(),\n",
    ")\n",
    "\n",
    "\n",
    "# Optimize the acquisition function\n",
    "candidates, _ = optimize_acqf(\n",
    "    acq_function=acq_func,\n",
    "    bounds=bounds,\n",
    "    q=1,#q: This is the number of points to sample in each step\n",
    "    num_restarts=10,#num_restarts: This is the number of starting points for the optimization.\n",
    "    raw_samples=1000,#raw_samples: This is the number of samples to draw when initializing the optimization\n",
    ")\n",
    "\n",
    "# Unnormalize the candidates\n",
    "candidates = candidates * (X.max(dim=0).values - X.min(dim=0).values) + X.min(dim=0).values\n",
    "\n",
    "#converting to dictionary\n",
    "next_param_dicts = [{param: value.item() for param, value in zip(paramConfig.keys(), next_param)} for next_param in candidates]\n",
    "\n",
    "print(next_param_dicts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
